{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302d462e",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cd1cc",
   "metadata": {},
   "source": [
    "# Problema\n",
    "Dado um conjunto de dados, como encontrar potenciais plágios e/ou duplicatas para remoção?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9127f",
   "metadata": {},
   "source": [
    "## Dados Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Gradient boosting ensembles sequentially add models to correct errors of prior ones.\",\n",
    "    \"SVMs operate by locating the hyperplane that maximally divides different categories.\",\n",
    "    \"Support vector machines work by finding a hyperplane that best separates classes.\",\n",
    "    \"Deep learning models can extract intricate patterns from data.\",\n",
    "    \"Overfitting happens when a model learns noise instead of the underlying pattern.\",\n",
    "    \"Decision trees split data based on feature thresholds to make predictions.\",\n",
    "    \"Activation functions introduce non-linearity into neural network layers.\",\n",
    "    \"Principal component analysis reduces dimensionality by projecting onto orthogonal axes.\",\n",
    "    \"This is an unrelated sentence about cooking recipes.\",\n",
    "    \"Data preprocessing is essential for machine learning success.\",\n",
    "    \"Batch normalization stabilizes learning by normalizing layer inputs.\",\n",
    "    \"Data preprocessing is essential for machine learning success.\",\n",
    "    \"From data, deep learning models are able to extract complex patterns.\",\n",
    "    \"Neural networks require large amounts of labeled training data.\",\n",
    "    \"Support vector machines classify data by identifying the optimal separating hyperplane between classes.\",\n",
    "    \"Reinforcement learning agents improve through trial and error interactions.\",\n",
    "    \"Cross-validation helps assess model generalization on unseen data.\",\n",
    "    \"Hyperparameter tuning finds the best configuration for model performance.\",\n",
    "    \"Neural networks demand substantial labeled data for training.\",\n",
    "    \"Clustering algorithms group points that are close in feature space.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404554f9",
   "metadata": {},
   "source": [
    "# Solução (Busca Vetorial entre Itens)\n",
    "A ideia é vetorizar todos os textos e checar a similaridade deste versus os outros.\n",
    "Aqueles que tiverem distância (dissimilaridade) próxima de `0` provavelmente são duplicatas ou tratam de temas extremamente parecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcb6bb",
   "metadata": {},
   "source": [
    "## Carregando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f46af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setando o modelo\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformerEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58d526",
   "metadata": {},
   "source": [
    "## Construindo o Banco Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo com o FAISS no LangChain\n",
    "vectordb = FAISS.from_texts(texts, embedding=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26404d",
   "metadata": {},
   "source": [
    "## Checando Semelhança Entre Itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 1.0 # Distância mínima para não ser considerado muito semelhante\n",
    "potential_dups = []\n",
    "\n",
    "for i in range(vectordb.index.ntotal):\n",
    "    # Olhamos um documento específico\n",
    "    doc_id = vectordb.index_to_docstore_id[i]\n",
    "    doc = vectordb.docstore.search(doc_id)\n",
    "\n",
    "    # Capturamos os top 4 mais semelhantes (3 + ele)\n",
    "    results = vectordb.similarity_search_with_score(query=doc.page_content, k=4)\n",
    "\n",
    "    # Coletamos todos que tem distância menor que 1, exceto ele próprio\n",
    "    suspects = [\n",
    "        other.page_content\n",
    "        for other, score in results\n",
    "        if other.page_content != doc.page_content and score < THRESHOLD\n",
    "    ]\n",
    "\n",
    "    # Guardamos o \"original\" e as potenciais duplicatas\n",
    "    if suspects:\n",
    "        potential_dups.append((doc.page_content, suspects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94991920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printando o resultado\n",
    "for original, duplicates in potential_dups:\n",
    "    print(f\"Original: {original}\")\n",
    "    for dup in duplicates:\n",
    "        print(f\"    Dup.: {dup}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dio-vectorial-databases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
